{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "https://www.kaggle.com/datasets/yacharki/yelp-reviews-for-sa-finegrained-5-classes-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   class_index                                        review_text\n",
       " 0            5  dr. goldberg offers everything i look for in a...\n",
       " 1            2  Unfortunately, the frustration of being Dr. Go...\n",
       " 2            4  Been going to Dr. Goldberg for over 10 years. ...\n",
       " 3            4  Got a letter in the mail last week that said D...\n",
       " 4            1  I don't know what Dr. Goldberg was like before...,\n",
       " 650000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./yelp_review_fine-grained_5_classes_csv/train.csv\")\n",
    "df.head(), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21394"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.review_text.apply(lambda x: len(str(x)) <= 85 and len(str(x)) >= 2)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review_text\"] = df[\"review_text\"].str.lower()\n",
    "df[\"review_text\"] = df[\"review_text\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21394"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how='all', axis=1, inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.98, random_state=42)\n",
    "df_test_model = df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN = np.max([len(str(rew)) for rew in df_train[\"review_text\"]])\n",
    "SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train[\"review_text\"]\n",
    "y_train = df_train[\"class_index\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xids =  np.zeros((len(df_train),SEQ_LEN))\n",
    "Xmask = np.zeros((len(df_train),SEQ_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sequence in enumerate(df_train[\"review_text\"]):\n",
    "    tokens = tokenizer.encode_plus(str(sequence), max_length=SEQ_LEN, truncation=True, padding=\"max_length\", add_special_tokens=True, return_token_type_ids=\"tf\")\n",
    "\n",
    "    Xids[i, :], Xmask[i, :] = tokens[\"input_ids\"], tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 2, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20966, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros((y_train.size, y_train.max()))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[np.arange(y_train.size), y_train-1] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 20:49:50.310380: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-20 20:49:50.947830: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 20:49:52.164799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 20:49:55.601628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 20:49:55.873162: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 20:49:55.873316: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 20:50:02.986774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 20:50:02.986838: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 20:50:02.986855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 20:50:04.267329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 20:50:04.267378: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 20:50:04.267384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-20 20:50:04.267408: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-20 20:50:04.267984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1768 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"input_ids\", dtype=\"int32\")\n",
    "mask = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"attention_mask\", dtype=\"int32\")\n",
    "\n",
    "embeddings = bert(input_ids, attention_mask=mask)[0]\n",
    "\n",
    "X = tf.keras.layers.GlobalMaxPooling1D()(embeddings)\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = tf.keras.layers.Dense(256, activation=\"relu\")(X)\n",
    "X = tf.keras.layers.Dropout(0.2)(X)\n",
    "X = tf.keras.layers.Dense(32, activation=\"relu\")(X)\n",
    "y = tf.keras.layers.Dense(5, activation=\"softmax\", name=\"outputs\")(X)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs = y)\n",
    "\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 85)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 85)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel  TFBaseModelOutputWithPooli   1094822   ['input_ids[0][0]',           \n",
      " )                           ngAndCrossAttentions(last_   40         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 85, 76                                           \n",
      "                             8),                                                                  \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 768)                  0         ['tf_bert_model[0][0]']       \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 768)                  3072      ['global_max_pooling1d[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  196864    ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)        (None, 256)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   8224      ['dropout_37[0][0]']          \n",
      "                                                                                                  \n",
      " outputs (Dense)             (None, 5)                    165       ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109690565 (418.44 MB)\n",
      "Trainable params: 206789 (807.77 KB)\n",
      "Non-trainable params: 109483776 (417.65 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy(\"accuracy\")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have saved the weights of the model, below is the place to load the weights and skip training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('./model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20966, 20966, 20966)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xids), len(Xmask), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xids = np.array(Xids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmask = np.array(Xmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718684278.551837    2044 service.cc:145] XLA service 0x7f78b49448d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1718684278.551899    2044 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-06-18 07:17:58.569396: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-18 07:17:58.597739: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1718684278.706527    2044 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 183s 605ms/step - loss: 1.2497 - accuracy: 0.4549 - val_loss: 1.1376 - val_accuracy: 0.5138\n",
      "Epoch 2/135\n",
      "263/263 [==============================] - 155s 589ms/step - loss: 1.1170 - accuracy: 0.5095 - val_loss: 1.1077 - val_accuracy: 0.5229\n",
      "Epoch 3/135\n",
      "263/263 [==============================] - 154s 585ms/step - loss: 1.0854 - accuracy: 0.5237 - val_loss: 1.1148 - val_accuracy: 0.5243\n",
      "Epoch 4/135\n",
      "263/263 [==============================] - 154s 588ms/step - loss: 1.0691 - accuracy: 0.5343 - val_loss: 1.0967 - val_accuracy: 0.5229\n",
      "Epoch 5/135\n",
      "263/263 [==============================] - 154s 588ms/step - loss: 1.0443 - accuracy: 0.5451 - val_loss: 1.1035 - val_accuracy: 0.5267\n",
      "Epoch 6/135\n",
      "263/263 [==============================] - 155s 588ms/step - loss: 1.0229 - accuracy: 0.5593 - val_loss: 1.1049 - val_accuracy: 0.5305\n",
      "Epoch 7/135\n",
      "263/263 [==============================] - 154s 587ms/step - loss: 1.0250 - accuracy: 0.5507 - val_loss: 1.1021 - val_accuracy: 0.5260\n",
      "Epoch 8/135\n",
      "263/263 [==============================] - 138s 524ms/step - loss: 1.0049 - accuracy: 0.5659 - val_loss: 1.1217 - val_accuracy: 0.5193\n",
      "Epoch 9/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.9910 - accuracy: 0.5659 - val_loss: 1.1129 - val_accuracy: 0.5262\n",
      "Epoch 10/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.9854 - accuracy: 0.5699 - val_loss: 1.1184 - val_accuracy: 0.5341\n",
      "Epoch 11/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.9608 - accuracy: 0.5808 - val_loss: 1.1204 - val_accuracy: 0.5315\n",
      "Epoch 12/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.9475 - accuracy: 0.5935 - val_loss: 1.1506 - val_accuracy: 0.5274\n",
      "Epoch 13/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.9416 - accuracy: 0.5962 - val_loss: 1.1299 - val_accuracy: 0.5234\n",
      "Epoch 14/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.9271 - accuracy: 0.6070 - val_loss: 1.1502 - val_accuracy: 0.5181\n",
      "Epoch 15/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.9253 - accuracy: 0.6072 - val_loss: 1.1457 - val_accuracy: 0.5196\n",
      "Epoch 16/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.9041 - accuracy: 0.6160 - val_loss: 1.1657 - val_accuracy: 0.5176\n",
      "Epoch 17/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.8936 - accuracy: 0.6195 - val_loss: 1.1595 - val_accuracy: 0.5119\n",
      "Epoch 18/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.8871 - accuracy: 0.6236 - val_loss: 1.1932 - val_accuracy: 0.5138\n",
      "Epoch 19/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.8701 - accuracy: 0.6311 - val_loss: 1.2001 - val_accuracy: 0.5091\n",
      "Epoch 20/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.8610 - accuracy: 0.6379 - val_loss: 1.2062 - val_accuracy: 0.5141\n",
      "Epoch 21/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.8479 - accuracy: 0.6449 - val_loss: 1.2007 - val_accuracy: 0.5150\n",
      "Epoch 22/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.8340 - accuracy: 0.6479 - val_loss: 1.2317 - val_accuracy: 0.5074\n",
      "Epoch 23/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.8241 - accuracy: 0.6542 - val_loss: 1.2334 - val_accuracy: 0.5007\n",
      "Epoch 24/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.8188 - accuracy: 0.6578 - val_loss: 1.2180 - val_accuracy: 0.5031\n",
      "Epoch 25/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.8135 - accuracy: 0.6607 - val_loss: 1.2489 - val_accuracy: 0.5114\n",
      "Epoch 26/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7935 - accuracy: 0.6668 - val_loss: 1.2576 - val_accuracy: 0.5122\n",
      "Epoch 27/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.7921 - accuracy: 0.6733 - val_loss: 1.2787 - val_accuracy: 0.5091\n",
      "Epoch 28/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7685 - accuracy: 0.6762 - val_loss: 1.2663 - val_accuracy: 0.5083\n",
      "Epoch 29/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7657 - accuracy: 0.6762 - val_loss: 1.3028 - val_accuracy: 0.5074\n",
      "Epoch 30/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7591 - accuracy: 0.6806 - val_loss: 1.2909 - val_accuracy: 0.4940\n",
      "Epoch 31/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7523 - accuracy: 0.6903 - val_loss: 1.3316 - val_accuracy: 0.5010\n",
      "Epoch 32/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7484 - accuracy: 0.6903 - val_loss: 1.3033 - val_accuracy: 0.5007\n",
      "Epoch 33/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7476 - accuracy: 0.6913 - val_loss: 1.3274 - val_accuracy: 0.5062\n",
      "Epoch 34/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.7233 - accuracy: 0.7021 - val_loss: 1.3508 - val_accuracy: 0.4967\n",
      "Epoch 35/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7324 - accuracy: 0.6955 - val_loss: 1.3303 - val_accuracy: 0.4959\n",
      "Epoch 36/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7192 - accuracy: 0.6995 - val_loss: 1.3390 - val_accuracy: 0.4981\n",
      "Epoch 37/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7129 - accuracy: 0.7094 - val_loss: 1.3697 - val_accuracy: 0.5014\n",
      "Epoch 38/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7060 - accuracy: 0.7129 - val_loss: 1.3769 - val_accuracy: 0.5021\n",
      "Epoch 39/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.7096 - accuracy: 0.7046 - val_loss: 1.3593 - val_accuracy: 0.5064\n",
      "Epoch 40/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.6975 - accuracy: 0.7133 - val_loss: 1.3778 - val_accuracy: 0.4917\n",
      "Epoch 41/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6940 - accuracy: 0.7154 - val_loss: 1.3816 - val_accuracy: 0.4948\n",
      "Epoch 42/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.6885 - accuracy: 0.7178 - val_loss: 1.4009 - val_accuracy: 0.5005\n",
      "Epoch 43/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6834 - accuracy: 0.7173 - val_loss: 1.3992 - val_accuracy: 0.4971\n",
      "Epoch 44/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.6836 - accuracy: 0.7213 - val_loss: 1.4161 - val_accuracy: 0.4852\n",
      "Epoch 45/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.6777 - accuracy: 0.7222 - val_loss: 1.4059 - val_accuracy: 0.4976\n",
      "Epoch 46/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6699 - accuracy: 0.7252 - val_loss: 1.4040 - val_accuracy: 0.4981\n",
      "Epoch 47/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6616 - accuracy: 0.7328 - val_loss: 1.4434 - val_accuracy: 0.4952\n",
      "Epoch 48/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6678 - accuracy: 0.7281 - val_loss: 1.4184 - val_accuracy: 0.4907\n",
      "Epoch 49/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6486 - accuracy: 0.7374 - val_loss: 1.4441 - val_accuracy: 0.4995\n",
      "Epoch 50/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.6542 - accuracy: 0.7336 - val_loss: 1.4441 - val_accuracy: 0.4936\n",
      "Epoch 51/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6507 - accuracy: 0.7337 - val_loss: 1.4640 - val_accuracy: 0.4907\n",
      "Epoch 52/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6435 - accuracy: 0.7449 - val_loss: 1.4346 - val_accuracy: 0.4890\n",
      "Epoch 53/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6389 - accuracy: 0.7411 - val_loss: 1.4686 - val_accuracy: 0.4936\n",
      "Epoch 54/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6471 - accuracy: 0.7346 - val_loss: 1.4571 - val_accuracy: 0.4967\n",
      "Epoch 55/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6429 - accuracy: 0.7412 - val_loss: 1.4435 - val_accuracy: 0.4931\n",
      "Epoch 56/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6355 - accuracy: 0.7444 - val_loss: 1.4581 - val_accuracy: 0.4917\n",
      "Epoch 57/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6228 - accuracy: 0.7477 - val_loss: 1.4832 - val_accuracy: 0.4905\n",
      "Epoch 58/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6248 - accuracy: 0.7487 - val_loss: 1.4645 - val_accuracy: 0.4962\n",
      "Epoch 59/135\n",
      "263/263 [==============================] - 120s 457ms/step - loss: 0.6139 - accuracy: 0.7542 - val_loss: 1.4761 - val_accuracy: 0.4905\n",
      "Epoch 60/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.6166 - accuracy: 0.7532 - val_loss: 1.5043 - val_accuracy: 0.4938\n",
      "Epoch 61/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6172 - accuracy: 0.7479 - val_loss: 1.5102 - val_accuracy: 0.5024\n",
      "Epoch 62/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.6093 - accuracy: 0.7527 - val_loss: 1.5029 - val_accuracy: 0.4857\n",
      "Epoch 63/135\n",
      "263/263 [==============================] - 121s 460ms/step - loss: 0.6110 - accuracy: 0.7495 - val_loss: 1.5184 - val_accuracy: 0.4921\n",
      "Epoch 64/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.6139 - accuracy: 0.7552 - val_loss: 1.4873 - val_accuracy: 0.4938\n",
      "Epoch 65/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.6136 - accuracy: 0.7550 - val_loss: 1.4748 - val_accuracy: 0.4917\n",
      "Epoch 66/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.6029 - accuracy: 0.7580 - val_loss: 1.4962 - val_accuracy: 0.4843\n",
      "Epoch 67/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.6031 - accuracy: 0.7573 - val_loss: 1.5144 - val_accuracy: 0.4995\n",
      "Epoch 68/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.5882 - accuracy: 0.7616 - val_loss: 1.4838 - val_accuracy: 0.4971\n",
      "Epoch 69/135\n",
      "263/263 [==============================] - 121s 460ms/step - loss: 0.5928 - accuracy: 0.7616 - val_loss: 1.4830 - val_accuracy: 0.4840\n",
      "Epoch 70/135\n",
      "263/263 [==============================] - 120s 458ms/step - loss: 0.5825 - accuracy: 0.7682 - val_loss: 1.5108 - val_accuracy: 0.4878\n",
      "Epoch 71/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.5856 - accuracy: 0.7655 - val_loss: 1.5001 - val_accuracy: 0.4902\n",
      "Epoch 72/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.5834 - accuracy: 0.7696 - val_loss: 1.4824 - val_accuracy: 0.4971\n",
      "Epoch 73/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.5823 - accuracy: 0.7685 - val_loss: 1.4947 - val_accuracy: 0.4959\n",
      "Epoch 74/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.5885 - accuracy: 0.7675 - val_loss: 1.5014 - val_accuracy: 0.5050\n",
      "Epoch 75/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5882 - accuracy: 0.7661 - val_loss: 1.5154 - val_accuracy: 0.5081\n",
      "Epoch 76/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5758 - accuracy: 0.7690 - val_loss: 1.5437 - val_accuracy: 0.5017\n",
      "Epoch 77/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.5775 - accuracy: 0.7702 - val_loss: 1.5009 - val_accuracy: 0.4983\n",
      "Epoch 78/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5769 - accuracy: 0.7708 - val_loss: 1.5317 - val_accuracy: 0.4986\n",
      "Epoch 79/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5777 - accuracy: 0.7705 - val_loss: 1.5493 - val_accuracy: 0.5017\n",
      "Epoch 80/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5665 - accuracy: 0.7772 - val_loss: 1.5473 - val_accuracy: 0.4971\n",
      "Epoch 81/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.5723 - accuracy: 0.7729 - val_loss: 1.5357 - val_accuracy: 0.4971\n",
      "Epoch 82/135\n",
      "263/263 [==============================] - 127s 482ms/step - loss: 0.5666 - accuracy: 0.7760 - val_loss: 1.5351 - val_accuracy: 0.5010\n",
      "Epoch 83/135\n",
      "263/263 [==============================] - 155s 589ms/step - loss: 0.5714 - accuracy: 0.7722 - val_loss: 1.5588 - val_accuracy: 0.4845\n",
      "Epoch 84/135\n",
      "263/263 [==============================] - 155s 590ms/step - loss: 0.5636 - accuracy: 0.7791 - val_loss: 1.5511 - val_accuracy: 0.4943\n",
      "Epoch 85/135\n",
      "263/263 [==============================] - 155s 590ms/step - loss: 0.5666 - accuracy: 0.7762 - val_loss: 1.5557 - val_accuracy: 0.4917\n",
      "Epoch 86/135\n",
      "263/263 [==============================] - 155s 590ms/step - loss: 0.5739 - accuracy: 0.7755 - val_loss: 1.5604 - val_accuracy: 0.4948\n",
      "Epoch 87/135\n",
      "263/263 [==============================] - 156s 592ms/step - loss: 0.5530 - accuracy: 0.7787 - val_loss: 1.5581 - val_accuracy: 0.4917\n",
      "Epoch 88/135\n",
      "263/263 [==============================] - 155s 590ms/step - loss: 0.5553 - accuracy: 0.7817 - val_loss: 1.5643 - val_accuracy: 0.4962\n",
      "Epoch 89/135\n",
      "263/263 [==============================] - 155s 589ms/step - loss: 0.5456 - accuracy: 0.7833 - val_loss: 1.6115 - val_accuracy: 0.4945\n",
      "Epoch 90/135\n",
      "263/263 [==============================] - 155s 589ms/step - loss: 0.5502 - accuracy: 0.7819 - val_loss: 1.5546 - val_accuracy: 0.4950\n",
      "Epoch 91/135\n",
      "263/263 [==============================] - 155s 588ms/step - loss: 0.5368 - accuracy: 0.7861 - val_loss: 1.6259 - val_accuracy: 0.4986\n",
      "Epoch 92/135\n",
      "263/263 [==============================] - 121s 460ms/step - loss: 0.5510 - accuracy: 0.7801 - val_loss: 1.5958 - val_accuracy: 0.4955\n",
      "Epoch 93/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.5453 - accuracy: 0.7851 - val_loss: 1.5627 - val_accuracy: 0.4890\n",
      "Epoch 94/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.5472 - accuracy: 0.7849 - val_loss: 1.5931 - val_accuracy: 0.5021\n",
      "Epoch 95/135\n",
      "263/263 [==============================] - 120s 457ms/step - loss: 0.5566 - accuracy: 0.7803 - val_loss: 1.5677 - val_accuracy: 0.4921\n",
      "Epoch 96/135\n",
      "263/263 [==============================] - 120s 455ms/step - loss: 0.5444 - accuracy: 0.7865 - val_loss: 1.5931 - val_accuracy: 0.5007\n",
      "Epoch 97/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.5277 - accuracy: 0.7912 - val_loss: 1.6044 - val_accuracy: 0.4900\n",
      "Epoch 98/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.5401 - accuracy: 0.7880 - val_loss: 1.5911 - val_accuracy: 0.4917\n",
      "Epoch 99/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5465 - accuracy: 0.7864 - val_loss: 1.6192 - val_accuracy: 0.4914\n",
      "Epoch 100/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5322 - accuracy: 0.7892 - val_loss: 1.5936 - val_accuracy: 0.4890\n",
      "Epoch 101/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5351 - accuracy: 0.7851 - val_loss: 1.5913 - val_accuracy: 0.4928\n",
      "Epoch 102/135\n",
      "263/263 [==============================] - 120s 458ms/step - loss: 0.5270 - accuracy: 0.7877 - val_loss: 1.5992 - val_accuracy: 0.4895\n",
      "Epoch 103/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5351 - accuracy: 0.7898 - val_loss: 1.6245 - val_accuracy: 0.4859\n",
      "Epoch 104/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5313 - accuracy: 0.7924 - val_loss: 1.5956 - val_accuracy: 0.4902\n",
      "Epoch 105/135\n",
      "263/263 [==============================] - 122s 463ms/step - loss: 0.5310 - accuracy: 0.7954 - val_loss: 1.6148 - val_accuracy: 0.4931\n",
      "Epoch 106/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5450 - accuracy: 0.7869 - val_loss: 1.5947 - val_accuracy: 0.4890\n",
      "Epoch 107/135\n",
      "263/263 [==============================] - 119s 452ms/step - loss: 0.5338 - accuracy: 0.7896 - val_loss: 1.5715 - val_accuracy: 0.4871\n",
      "Epoch 108/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5213 - accuracy: 0.7962 - val_loss: 1.5970 - val_accuracy: 0.4862\n",
      "Epoch 109/135\n",
      "263/263 [==============================] - 119s 452ms/step - loss: 0.5356 - accuracy: 0.7873 - val_loss: 1.5956 - val_accuracy: 0.4902\n",
      "Epoch 110/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.5292 - accuracy: 0.7952 - val_loss: 1.6103 - val_accuracy: 0.4957\n",
      "Epoch 111/135\n",
      "263/263 [==============================] - 119s 452ms/step - loss: 0.5263 - accuracy: 0.7904 - val_loss: 1.5904 - val_accuracy: 0.4886\n",
      "Epoch 112/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.5286 - accuracy: 0.7906 - val_loss: 1.6018 - val_accuracy: 0.4857\n",
      "Epoch 113/135\n",
      "263/263 [==============================] - 119s 452ms/step - loss: 0.5187 - accuracy: 0.7986 - val_loss: 1.6042 - val_accuracy: 0.4990\n",
      "Epoch 114/135\n",
      "263/263 [==============================] - 119s 451ms/step - loss: 0.5321 - accuracy: 0.7920 - val_loss: 1.5751 - val_accuracy: 0.4921\n",
      "Epoch 115/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5217 - accuracy: 0.7959 - val_loss: 1.5848 - val_accuracy: 0.4862\n",
      "Epoch 116/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.5208 - accuracy: 0.7961 - val_loss: 1.6124 - val_accuracy: 0.4897\n",
      "Epoch 117/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.5083 - accuracy: 0.7987 - val_loss: 1.6045 - val_accuracy: 0.4964\n",
      "Epoch 118/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.5101 - accuracy: 0.8018 - val_loss: 1.5855 - val_accuracy: 0.4948\n",
      "Epoch 119/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5109 - accuracy: 0.8000 - val_loss: 1.6218 - val_accuracy: 0.4909\n",
      "Epoch 120/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.5112 - accuracy: 0.8009 - val_loss: 1.6177 - val_accuracy: 0.4938\n",
      "Epoch 121/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.5154 - accuracy: 0.7993 - val_loss: 1.6122 - val_accuracy: 0.4905\n",
      "Epoch 122/135\n",
      "263/263 [==============================] - 119s 453ms/step - loss: 0.5100 - accuracy: 0.8001 - val_loss: 1.6236 - val_accuracy: 0.4943\n",
      "Epoch 123/135\n",
      "263/263 [==============================] - 119s 454ms/step - loss: 0.5035 - accuracy: 0.8033 - val_loss: 1.6357 - val_accuracy: 0.4890\n",
      "Epoch 124/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.5125 - accuracy: 0.7994 - val_loss: 1.6220 - val_accuracy: 0.4831\n",
      "Epoch 125/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.5095 - accuracy: 0.7999 - val_loss: 1.6521 - val_accuracy: 0.4897\n",
      "Epoch 126/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.5078 - accuracy: 0.8017 - val_loss: 1.6571 - val_accuracy: 0.4804\n",
      "Epoch 127/135\n",
      "263/263 [==============================] - 120s 458ms/step - loss: 0.5018 - accuracy: 0.8021 - val_loss: 1.6362 - val_accuracy: 0.4816\n",
      "Epoch 128/135\n",
      "263/263 [==============================] - 120s 457ms/step - loss: 0.5074 - accuracy: 0.7995 - val_loss: 1.6313 - val_accuracy: 0.4845\n",
      "Epoch 129/135\n",
      "263/263 [==============================] - 120s 457ms/step - loss: 0.5066 - accuracy: 0.7991 - val_loss: 1.6303 - val_accuracy: 0.4862\n",
      "Epoch 130/135\n",
      "263/263 [==============================] - 120s 457ms/step - loss: 0.5045 - accuracy: 0.8016 - val_loss: 1.6342 - val_accuracy: 0.4914\n",
      "Epoch 131/135\n",
      "263/263 [==============================] - 120s 457ms/step - loss: 0.5035 - accuracy: 0.8038 - val_loss: 1.6662 - val_accuracy: 0.4907\n",
      "Epoch 132/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.4961 - accuracy: 0.8056 - val_loss: 1.6495 - val_accuracy: 0.4943\n",
      "Epoch 133/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.4961 - accuracy: 0.8034 - val_loss: 1.6512 - val_accuracy: 0.4847\n",
      "Epoch 134/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.4810 - accuracy: 0.8099 - val_loss: 1.6781 - val_accuracy: 0.4826\n",
      "Epoch 135/135\n",
      "263/263 [==============================] - 120s 456ms/step - loss: 0.4925 - accuracy: 0.8091 - val_loss: 1.6593 - val_accuracy: 0.4897\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([Xids, Xmask], labels, validation_split=0.2, epochs=135, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(review):\n",
    "    tokens = tokenizer.encode_plus(review, max_length=SEQ_LEN, truncation=True, padding=\"max_length\", add_special_tokens=True, return_token_type_ids=False, return_attention_mask=True, return_tensors='tf')\n",
    "    x = np.array(tokens[\"input_ids\"])\n",
    "    y = np.array(tokens[\"attention_mask\"])\n",
    "    return (model.predict([x,y], verbose=0).argmax(axis=1) + 1)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the wieghts of the model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights(\"./model.hdf5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try model with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_model[\"prediction\"] = df_test_model[\"review_text\"].apply(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_index</th>\n",
       "      <th>review_text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>2</td>\n",
       "      <td>appearance is best\\nthe drinks and food don't ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>4</td>\n",
       "      <td>excellent food with great service.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>2</td>\n",
       "      <td>okay food.  number of other guests is often ze...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>1</td>\n",
       "      <td>my wife got food poisoning from here. avoid at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>1</td>\n",
       "      <td>went there last night, great concept, good loo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631343</th>\n",
       "      <td>3</td>\n",
       "      <td>it was a good change of pace. don't know how s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638217</th>\n",
       "      <td>5</td>\n",
       "      <td>love this place!! $1 u call it's, beautiful gi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640017</th>\n",
       "      <td>1</td>\n",
       "      <td>just like predicted, business is closed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645463</th>\n",
       "      <td>5</td>\n",
       "      <td>lilac is the best groomer in town. wouldn't go...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648249</th>\n",
       "      <td>1</td>\n",
       "      <td>absolute joke. 1hr check in. 40 people in line...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class_index                                        review_text  \\\n",
       "4166              2  appearance is best\\nthe drinks and food don't ...   \n",
       "4805              4                 excellent food with great service.   \n",
       "4807              2  okay food.  number of other guests is often ze...   \n",
       "4856              1  my wife got food poisoning from here. avoid at...   \n",
       "4946              1  went there last night, great concept, good loo...   \n",
       "...             ...                                                ...   \n",
       "631343            3  it was a good change of pace. don't know how s...   \n",
       "638217            5  love this place!! $1 u call it's, beautiful gi...   \n",
       "640017            1            just like predicted, business is closed   \n",
       "645463            5  lilac is the best groomer in town. wouldn't go...   \n",
       "648249            1  absolute joke. 1hr check in. 40 people in line...   \n",
       "\n",
       "        prediction  \n",
       "4166             2  \n",
       "4805             5  \n",
       "4807             3  \n",
       "4856             1  \n",
       "4946             2  \n",
       "...            ...  \n",
       "631343           4  \n",
       "638217           5  \n",
       "640017           1  \n",
       "645463           5  \n",
       "648249           4  \n",
       "\n",
       "[428 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/65618137/confusion-matrix-for-multiple-classes-in-python\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.521\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "score = metrics.accuracy_score(df_test_model[\"class_index\"], df_test_model[\"prediction\"])\n",
    "#score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "cm = metrics.confusion_matrix(df_test_model[\"class_index\"], df_test_model[\"prediction\"])\n",
    "#cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm, classes=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably more epochs needed for better results and/or improved model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
